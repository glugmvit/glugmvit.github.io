---
layout: post
title:  "Docker: Using Containers"
author: vipul
mathjax: true
featured: true
image: assets/images/docker-logo.png
excerpt: Docker provides the power of deployment to the developer giving the much needed transition to operations.
---
# Docker: Using Containers (PART 2) 
Let us dive right into hands-on coding to use containers in Docker.

```console
$ sudo docker run hello-world
```
You can skip the sudo if you are running docker as adminstrator.
You should get the following message if the installation was successfull:
![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/10.png) <br/>
Let us see what exactly happend behind the scenes here:<br/>

![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/11.png)<br/>
The following steps took place to display the above output:
1. Our command instructed the computer to run the docker image called hello-world
2. The hello-world image was fetched from the Docker Hub
3. If the image was locally available then it will be fetched from the cache
4. The computer runs the image on local machine
5. Stop the container

So, the bigger question is where do these images come from??
When the container image is not present locally then it is fetched from a registry on DockerHub online which is a collection of all the container images. DockerHub is a paid registry which allows unlimited storage and access for public registries and restricted access for premium registeries. It can be accessed on https://hub.docker.com/. You will have to sign up on this website in order to publish any images to the Docker registry. So, before proceeding further go sign up on the above link!
To access the account through the terminal for uploading images, execute the following command and answer the prompt of login details:
```console
$ sudo docker login
```
If we wish to upload an image to the registry, we use the following command:

```console
$ sudo docker push image-name
```
where image-name will be the title of your container image.
If we wish to access the various commands or debugging logs we can use the following command:
```console
$ sudo docker run --help
```
Some of the options for docker command manipulations are:
1. docker logs: It provides a view to the entire detailed logs of execution and after stopping as well.
2. docker ps: Lists all the running container images and if used with the option -a it also displays the stopped containers.
3. docker stop: Used to stop a running container.
4. docker rm: Deletes a container.
5. docker inspect: Get details of the container
Let us try out some of these commands!
```console
$ sudo docker ps
```
![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/docker2.1.png)<br/>
We get the list of containers running currently with their dates of creation and unique IDs.
```console
$ sudo docker ps -a
```
![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/docker2.2.png)<br/>
It displays the stopped containers as well.
```console
$ sudo docker inspect container-id
```
We use the container id of the nginx image specified in the above illustration.
When we inspect it we get a detailed log whose small part is illustrated below.
![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/docker2.3.png)<br/>
Now, let us talk about the docker run command more in detail.
The run command is analogous to setting up a new machine with brand new programs for execution. It allows the creation of same image multiple times in different containers as well. This feature makes it useful in executing similar or dissimilar processes in parallel. Say for example, if we run the following commands:
```console
$ sudo docker run alpine printenv
$ sudo docker run alpine printenv
```
Alpine is a small package in Linux registry and the run command will fetch it from the Docker Hub initially since it is not available on the local system then it will execute the method printenv present in the package. However, it will assign different hosts with unique IDs to each command even if they are same.
An alternate to remove stopped containers without specifying their unique ID is to use the following command:
```console
$ sudo docker container prune -f
```
It removes any inactive containers and the -f switch is an implicit confirmation to proceed and delete all stopped containers right away, instead of asking to confirm that operation.
Now, we wish to permanently store data in the containers. Till now whatever information we processed is lost when we stopped the container. Hence, we are going to classify containers based on this:
1. Stateful Containers: These containers store the information even after being stopped and retain the contents after its resumption.
2. Stateless Containers: They lose all the information processed as soon as it stops.

The internet makes use of long lived running containers for network connections called server containers. Let us illustrate it with the following example:
```console
$ sudo docker run alpine ping www.docker.com
```

![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/1.png)<br/>
The ping command will not stop as the server is hosted and continously running in the background and we have to press Ctrl+C to stop the execution of command. If we add -d switch the execution will not display output and only the container is initialized. We can also specify port number explicity to run a server container on a specific network connection as follows:
```console
$ sudo docker run -d -p 8085:80 nginx
```
This command will run the server named nginx on port number 80 with -d switch indicating that it will run in the background. To check it out you can visit http://localhost:8085 :<br/>
![alt-text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/4.png)<br/>
If you get the above message it successfully executed!
The best part about this is that containers isolate all the processes within itself and will not affect or be affected by the processes occuring on the local machine. It ensures that each software deployed through a container meets its own requirements without affecting the specifications of the rest of the system.
Let us try running a Jenkins server as a wrap up for this post.

```console
$ sudo docker run -d -p 8088:8080 jenkins
```
We will get the following processing command at http://localhost:8088 :<br/>
![alt-text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/5.png)<br/>
Once you sign up and login then:<br/>
![alt text](https://raw.githubusercontent.com/vgaurav3011/glugmvit.github.io/master/assets/images/docker/6.png)<br/>
We can now continously integrate server and make changes with the localhost within the container without affecting any external processes. In the next post, we will try learn to create and publish our own docker images! Cheers!
